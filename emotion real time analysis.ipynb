{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotion real time analysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9ECaBLCTe9ik","colab_type":"code","outputId":"d9b8fd22-6700-4143-dcc6-c67985b87962","executionInfo":{"status":"ok","timestamp":1569256182943,"user_tz":-330,"elapsed":27365,"user":{"displayName":"MRINAL WALIA","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE3GWqUZxcTnQbIY2jcPRnVSYqkpYySP_8tLGgNA=s64","userId":"13551350199368331612"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-tkqZJR6fRh4","colab_type":"code","outputId":"0b57916d-56e0-4529-afa4-479281179f4a","executionInfo":{"status":"ok","timestamp":1569256641641,"user_tz":-330,"elapsed":457386,"user":{"displayName":"MRINAL WALIA","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE3GWqUZxcTnQbIY2jcPRnVSYqkpYySP_8tLGgNA=s64","userId":"13551350199368331612"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import sys, os\n","import pandas as pd\n","import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n","from keras.losses import categorical_crossentropy\n","from keras.optimizers import Adam\n","from keras.regularizers import l2\n","from keras.utils import np_utils\n","# pd.set_option('display.max_rows', 500)\n","# pd.set_option('display.max_columns', 500)\n","# pd.set_option('display.width', 1000)\n","\n","df=pd.read_csv('gdrive/My Drive/fer2013.csv')\n","\n","# print(df.info())\n","# print(df[\"Usage\"].value_counts())\n","\n","# print(df.head())\n","X_train,train_y,X_test,test_y=[],[],[],[]\n","\n","for index, row in df.iterrows():\n","    val=row['pixels'].split(\" \")\n","    try:\n","        if 'Training' in row['Usage']:\n","           X_train.append(np.array(val,'float32'))\n","           train_y.append(row['emotion'])\n","        elif 'PublicTest' in row['Usage']:\n","           X_test.append(np.array(val,'float32'))\n","           test_y.append(row['emotion'])\n","    except:\n","        print(f\"error occured at index :{index} and row:{row}\")\n","\n","\n","num_features = 64\n","num_labels = 7\n","batch_size = 64\n","epochs = 45\n","width, height = 48, 48\n","\n","\n","X_train = np.array(X_train,'float32')\n","train_y = np.array(train_y,'float32')\n","X_test = np.array(X_test,'float32')\n","test_y = np.array(test_y,'float32')\n","\n","train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n","test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n","\n","#cannot produce\n","#normalizing data between oand 1\n","X_train -= np.mean(X_train, axis=0)\n","X_train /= np.std(X_train, axis=0)\n","\n","X_test -= np.mean(X_test, axis=0)\n","X_test /= np.std(X_test, axis=0)\n","\n","X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n","\n","X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n","\n","# print(f\"shape:{X_train.shape}\")\n","##designing the cnn\n","#1st convolution layer\n","model = Sequential()\n","\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n","model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n","# model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","#2nd convolution layer\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","# model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","#3rd convolution layer\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","# model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n","\n","model.add(Flatten())\n","\n","#fully connected neural networks\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(num_labels, activation='softmax'))\n","\n","# model.summary()\n","\n","#Compliling the model\n","model.compile(loss=categorical_crossentropy,\n","              optimizer=Adam(),\n","              metrics=['accuracy'])\n","\n","#Training the model\n","model.fit(X_train, train_y,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(X_test, test_y),\n","          shuffle=True)\n","\n","#Saving the  model to  use it later on\n","fer_json = model.to_json()\n","with open(\"fer.json\", \"w\") as json_file:\n","    json_file.write(fer_json)\n","model.save_weights(\"fer.h5\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 28709 samples, validate on 3589 samples\n","Epoch 1/45\n","28709/28709 [==============================] - 17s 606us/step - loss: 1.7268 - acc: 0.2913 - val_loss: 1.5492 - val_acc: 0.3870\n","Epoch 2/45\n","28709/28709 [==============================] - 9s 313us/step - loss: 1.5026 - acc: 0.4091 - val_loss: 1.3748 - val_acc: 0.4597\n","Epoch 3/45\n","28709/28709 [==============================] - 9s 313us/step - loss: 1.3896 - acc: 0.4648 - val_loss: 1.3113 - val_acc: 0.4865\n","Epoch 4/45\n","28709/28709 [==============================] - 9s 312us/step - loss: 1.3227 - acc: 0.4886 - val_loss: 1.2633 - val_acc: 0.5068\n","Epoch 5/45\n","28709/28709 [==============================] - 9s 314us/step - loss: 1.2816 - acc: 0.5067 - val_loss: 1.2400 - val_acc: 0.5194\n","Epoch 6/45\n","28709/28709 [==============================] - 9s 314us/step - loss: 1.2426 - acc: 0.5241 - val_loss: 1.2220 - val_acc: 0.5230\n","Epoch 7/45\n","28709/28709 [==============================] - 9s 315us/step - loss: 1.2090 - acc: 0.5351 - val_loss: 1.1996 - val_acc: 0.5386\n","Epoch 8/45\n","28709/28709 [==============================] - 9s 317us/step - loss: 1.1857 - acc: 0.5457 - val_loss: 1.1692 - val_acc: 0.5467\n","Epoch 9/45\n","28709/28709 [==============================] - 9s 319us/step - loss: 1.1647 - acc: 0.5515 - val_loss: 1.1753 - val_acc: 0.5483\n","Epoch 10/45\n","28709/28709 [==============================] - 9s 317us/step - loss: 1.1428 - acc: 0.5613 - val_loss: 1.1673 - val_acc: 0.5495\n","Epoch 11/45\n","28709/28709 [==============================] - 9s 319us/step - loss: 1.1244 - acc: 0.5686 - val_loss: 1.1501 - val_acc: 0.5536\n","Epoch 12/45\n","28709/28709 [==============================] - 9s 319us/step - loss: 1.1085 - acc: 0.5749 - val_loss: 1.1698 - val_acc: 0.5511\n","Epoch 13/45\n","28709/28709 [==============================] - 9s 318us/step - loss: 1.0854 - acc: 0.5879 - val_loss: 1.1574 - val_acc: 0.5595\n","Epoch 14/45\n","28709/28709 [==============================] - 9s 320us/step - loss: 1.0621 - acc: 0.5892 - val_loss: 1.1738 - val_acc: 0.5626\n","Epoch 15/45\n","28709/28709 [==============================] - 9s 319us/step - loss: 1.0502 - acc: 0.6001 - val_loss: 1.1601 - val_acc: 0.5589\n","Epoch 16/45\n","28709/28709 [==============================] - 9s 320us/step - loss: 1.0295 - acc: 0.6050 - val_loss: 1.1473 - val_acc: 0.5642\n","Epoch 17/45\n","28709/28709 [==============================] - 9s 321us/step - loss: 1.0168 - acc: 0.6155 - val_loss: 1.1437 - val_acc: 0.5678\n","Epoch 18/45\n","28709/28709 [==============================] - 9s 327us/step - loss: 0.9990 - acc: 0.6173 - val_loss: 1.1410 - val_acc: 0.5690\n","Epoch 19/45\n","28709/28709 [==============================] - 9s 321us/step - loss: 0.9856 - acc: 0.6240 - val_loss: 1.1453 - val_acc: 0.5681\n","Epoch 20/45\n","28709/28709 [==============================] - 9s 322us/step - loss: 0.9701 - acc: 0.6287 - val_loss: 1.1326 - val_acc: 0.5765\n","Epoch 21/45\n","28709/28709 [==============================] - 9s 322us/step - loss: 0.9539 - acc: 0.6378 - val_loss: 1.1972 - val_acc: 0.5740\n","Epoch 22/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.9392 - acc: 0.6386 - val_loss: 1.1562 - val_acc: 0.5684\n","Epoch 23/45\n","28709/28709 [==============================] - 9s 323us/step - loss: 0.9386 - acc: 0.6425 - val_loss: 1.1711 - val_acc: 0.5667\n","Epoch 24/45\n","28709/28709 [==============================] - 9s 323us/step - loss: 0.9154 - acc: 0.6520 - val_loss: 1.1582 - val_acc: 0.5676\n","Epoch 25/45\n","28709/28709 [==============================] - 9s 326us/step - loss: 0.9056 - acc: 0.6531 - val_loss: 1.1388 - val_acc: 0.5762\n","Epoch 26/45\n","28709/28709 [==============================] - 9s 326us/step - loss: 0.8911 - acc: 0.6570 - val_loss: 1.1589 - val_acc: 0.5712\n","Epoch 27/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.8749 - acc: 0.6669 - val_loss: 1.1802 - val_acc: 0.5804\n","Epoch 28/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.8668 - acc: 0.6719 - val_loss: 1.1751 - val_acc: 0.5704\n","Epoch 29/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.8483 - acc: 0.6755 - val_loss: 1.1892 - val_acc: 0.5756\n","Epoch 30/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.8325 - acc: 0.6834 - val_loss: 1.2105 - val_acc: 0.5731\n","Epoch 31/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.8302 - acc: 0.6823 - val_loss: 1.2042 - val_acc: 0.5734\n","Epoch 32/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.8138 - acc: 0.6935 - val_loss: 1.2185 - val_acc: 0.5673\n","Epoch 33/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.8013 - acc: 0.7009 - val_loss: 1.2306 - val_acc: 0.5754\n","Epoch 34/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.7903 - acc: 0.7026 - val_loss: 1.2314 - val_acc: 0.5787\n","Epoch 35/45\n","28709/28709 [==============================] - 9s 326us/step - loss: 0.7788 - acc: 0.7065 - val_loss: 1.2337 - val_acc: 0.5659\n","Epoch 36/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.7705 - acc: 0.7101 - val_loss: 1.2149 - val_acc: 0.5798\n","Epoch 37/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.7524 - acc: 0.7134 - val_loss: 1.2313 - val_acc: 0.5754\n","Epoch 38/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.7577 - acc: 0.7136 - val_loss: 1.2923 - val_acc: 0.5795\n","Epoch 39/45\n","28709/28709 [==============================] - 9s 326us/step - loss: 0.7356 - acc: 0.7243 - val_loss: 1.2554 - val_acc: 0.5743\n","Epoch 40/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.7320 - acc: 0.7265 - val_loss: 1.2403 - val_acc: 0.5821\n","Epoch 41/45\n","28709/28709 [==============================] - 9s 326us/step - loss: 0.7245 - acc: 0.7281 - val_loss: 1.2440 - val_acc: 0.5829\n","Epoch 42/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.7109 - acc: 0.7321 - val_loss: 1.2267 - val_acc: 0.5695\n","Epoch 43/45\n","28709/28709 [==============================] - 9s 325us/step - loss: 0.6970 - acc: 0.7388 - val_loss: 1.2663 - val_acc: 0.5782\n","Epoch 44/45\n","28709/28709 [==============================] - 9s 324us/step - loss: 0.6895 - acc: 0.7433 - val_loss: 1.2465 - val_acc: 0.5901\n","Epoch 45/45\n","28709/28709 [==============================] - 9s 326us/step - loss: 0.6802 - acc: 0.7487 - val_loss: 1.2637 - val_acc: 0.5701\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f2wb1SPdvbzq","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download(\"fer.h5\")\n","#files.download('fer.json')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pv5ufIUPpiD6","colab_type":"code","colab":{}},"source":["fer_json = model.to_json()\n","with open(\"gdrive/My Drive/fer.json\", \"w\") as json_file:\n","    json_file.write(fer_json)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3oErEiUb3Pd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}